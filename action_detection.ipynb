{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsbm3P7zOmpV2cozj+jP7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarkhelranit-source/Machine-Learning/blob/master/action_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import Dependencies"
      ],
      "metadata": {
        "id": "AqYpj1c3gzIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XclKbScmfxjf"
      },
      "outputs": [],
      "source": [
        "!pip install -U matplotlib tensorflow scikit-learn opencv-python mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "HuRzz6biu1Mr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KeyPoints Using MP Holistic"
      ],
      "metadata": {
        "id": "blO1uFn0uQQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_holistic = mp.solutions.holistic # Bringing the Holistic Model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing Utilities"
      ],
      "metadata": {
        "id": "dKF50g6IykZe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mediapipe_detection(image, model):\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION FROM BGR 2 RGB (B:Blue, G:Green, R:Red)\n",
        "  image.flags.writeable = False                  # Image is no longer writeable\n",
        "  results = model.process(image)                 # Making Prediction\n",
        "  image.flags.writeable = True                   # Image is now writeable\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR CONVERSION FROM RGB 2 BGR\n",
        "  return image, results"
      ],
      "metadata": {
        "id": "LAbT-4vE1ZOr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_landmarks(image, results):\n",
        "  mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\n",
        "  mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "  mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "  mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
      ],
      "metadata": {
        "id": "MdKYcc6l6wOC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture = cv2.VideoCapture(0)\n",
        "\n",
        "# Access mediapipe model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  while capture.isOpened():\n",
        "    # Read Feed\n",
        "    ret, frame = capture.read()\n",
        "\n",
        "    # Make detections\n",
        "    image, results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "    # Show to Screen\n",
        "    cv2.imshow('OpenCV Feed', frame)\n",
        "\n",
        "    # Break the loop\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "  capture.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "iPj2ZzZDuYdA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "h1MNHBzi83re"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Keypoint Values"
      ],
      "metadata": {
        "id": "iHZUgGOmx-Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cm-mQn1SyB0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
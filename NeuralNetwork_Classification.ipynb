{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to neural network classification with Tensorflow\n",
    "\n",
    "In this notebook we're going to learn how to write neural networks for classification problems.\n",
    "\n",
    "A classification is where you try to classify something as one thing or another\n",
    "* Binary classification\n",
    "* Multiclass classification\n",
    "* Multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Make 1000 circles\n",
    "n_samples = 1000\n",
    "\n",
    "# Create circles\n",
    "X, Y = make_circles(n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(X), Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a little hard to understand right now... Let's visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":Y})\n",
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling\n",
    "\n",
    "The steps in modelling with Tensorflow are typically\n",
    "\n",
    "1. Create or import a model\n",
    "2. Compile the model\n",
    "3. Fit the model\n",
    "4. Evaluate the model\n",
    "5. Tweak\n",
    "6. Evaluate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model using Sequential API\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X, Y, epochs=150, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model_1.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our  model's predictions, let's create a function `plot_decision_boundary()`, this function will:\n",
    "    \n",
    "* Take in a trained model, features (X) and labels(Y)\n",
    "* Create a meshgrid of the different X values\n",
    "* Make predictions across the meshgrid\n",
    "* Plot the predictions as well as line between zones (where each unique class falls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, Y):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary created by a model predicting on X.\n",
    "    \"\"\"\n",
    "    # Define the axis boundary of the plot and create the meshgrid\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Create X value (we're going to make predictions on this)\n",
    "    x_in = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_in)\n",
    "    \n",
    "    # Check for multi-class\n",
    "    if len(y_pred[0]) > 1:\n",
    "        print(\"Doing multiclass classification\")\n",
    "        # We have to reshape our predictions to get them ready for plotting\n",
    "        y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
    "    else:\n",
    "        print(\"Doing binary classification\")\n",
    "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
    "        \n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=0.7)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the predictions our model is making\n",
    "plot_decision_boundary(model=model_1, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "\n",
    "x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Missing Piece: Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = model_2.fit(X, Y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the decision boundary for our latest model\n",
    "plot_decision_boundary(model=model_2, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” **Question:** What's wrong with the predictions we've made? Are we really evaluating our model correctly? Hint: What data did the model learned on and what data did we predict on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy tensor (similar to the data we pass into our models)\n",
    "A = tf.cast(tf.range(-10, 10), tf.float32)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by replicating sigmoid - sigmoid(x) = 1/(1+exp(-x))\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "# Using this sigmoid function now on our toy tensor\n",
    "sigmoid(A)\n",
    "   \n",
    "plt.plot(sigmoid(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the relu function\n",
    "def relu(x):\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "# Let's plot our toy tensor using relu function\n",
    "plt.plot(relu(A))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Improving our classification model\n",
    "\n",
    "So far we've been training and testing on the same dataset...\n",
    "\n",
    "However, in machine learning this is a sin,\n",
    "\n",
    "So let's create a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many examples we have\n",
    "len(X)\n",
    "\n",
    "# Split into train and tests sets\n",
    "X_train, Y_train = X[:800], Y[:800]\n",
    "\n",
    "X_test, Y_test = X[800:], Y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate a model to fit in the training data and evaluating in the testing data\n",
    "\n",
    "# Set a random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "final_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "final_model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = final_model.fit(X_train, Y_train, epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "final_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the decision boundary\n",
    "plot_decision_boundary(model=final_model, X=X_test, Y=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss (or training) curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(his.history).plot()\n",
    "plt.title(\"final_model loss curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”‘ **Note:** For many problems, the loss function goinng down means the model is improving (The predictions it's making are getting closer to the ground truth labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best learning rate\n",
    "\n",
    "To find the ideal learning rate (The learning rate where the loss decreases the most during the training) we're going to use the following steps:\n",
    "* A learning rate **callback** - we can think of a callback as an extra piece of functionality, we can add to the model while its training.\n",
    "* Another  model (we could use the same one as above, but we're practicing building models here).\n",
    "* A modified loss curves plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "from gc import callbacks\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Create a learning rate callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n",
    "\n",
    "# Fit the model\n",
    "his = model_3.fit(X_train, Y_train, epochs=100, callbacks=[lr_scheduler], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model_3\n",
    "model_3.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the plot history\n",
    "pd.DataFrame(his.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_4.fit(X_train, Y_train, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model_4\n",
    "model_4.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More classification evaluation methods\n",
    "\n",
    "Alongside visualizing our models results as much as possible, there are a handful of other classification evaluation methods & metrics we should be fimiliar with\n",
    "* Accuarcy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "* Confusion matrix\n",
    "* Classification report (from sklearn) - [Read the Docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of our model\n",
    "loss, accuracy = model_4.evaluate(X_test, Y_test)\n",
    "print(f\"Model loss on the test set: {loss}\")\n",
    "print(f\"Model accuracy on the test set: {(accuracy*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about a confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craete confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions \n",
    "Y_pred = model_4.predict(X_test)\n",
    "\n",
    "# Create a confusion_matrix\n",
    "confusion_matrix(Y_test, tf.squeeze(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our prediction array has turned out in **prediction probability** form... The standard output from the sigmoid activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our prediction probabilities to binary format and view the first 10\n",
    "Y_pred1 = tf.round(Y_pred)\n",
    "Y_pred1 =tf.cast(Y_pred1, dtype=tf.int64)\n",
    "Y_pred1 = tf.squeeze(Y_pred1)\n",
    "Y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about prettify our confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def make_confusion_matrix(matrix, cmap, title, xlabel, ylabel, classes=None):\n",
    "    ax = sns.heatmap(matrix, annot=True, cmap=cmap)\n",
    "    ax.set_title(f\"{title}\\n\\n\")\n",
    "    ax.set_xlabel(f\"\\n{xlabel}\")\n",
    "    ax.set_ylabel(f\"{ylabel}\")\n",
    "\n",
    "    # Plotting the Matrix\n",
    "    plt.show()\n",
    "\n",
    "make_confusion_matrix(cf_matrix, \"Oranges\", \"Seaborn Confusion Matrix\", \"Predicted Values\", \"Actual Values\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Multiclass Classification\n",
    "\n",
    "When we have more than two classes as an option, it's known as **multi-class-classfication**.\n",
    "* This means if we have 3 differrent classes, it's a multi-class-classfication.\n",
    "* It also means if you have 100 different classes, it's a multi-class-classfication.\n",
    "\n",
    "To practice multi-class-classfication, we're going to build a neural network to classify images of different items of clothing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The data is already been sorted into training and test sets for us\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first training sample\n",
    "print(f\"Training sample:\\n{train_data[2]}\\n\")\n",
    "print(f\"Training labels: {train_labels[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of a single example\n",
    "train_data[2].shape, train_labels[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single sample\n",
    "plt.imshow(train_data[7]), train_labels[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple random images of fashion MNIST\n",
    "import random\n",
    "plt.figure(figsize=(5, 5))\n",
    "for item in range(4):\n",
    "    ax = plt.subplot(2, 2, item+1)\n",
    "    rand_index = random.choice(range(len(train_data)))\n",
    "    plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multiclass classification model\n",
    "\n",
    "For our multiclass classifiaction model we can use the similar architecture to our binary classifiers, however, we're going to have to tweak a few things:\n",
    "* Input shape = 28 x 28 (the shape of one image)\n",
    "* Output shape = 10 (one per class of clothing)\n",
    "* Loss function = tf.keras.losses.CategoricalCrossentropy()\n",
    "  * If the labels are one-hot encoded use the CategoricalCrossentropy(). \n",
    "  * If the labels are in integer form use the SparseCategoricalCrossentropy().\n",
    "* Output layer activation = **softmax** instead of **sigmoid**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "clothing_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "clothing_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = clothing_model.fit(train_data, train_labels, epochs=10, validation_data=(test_data, test_labels), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "clothing_model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model summary\n",
    "clothing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the min and max values of the training data\n",
    "train_data.min(), train_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks prefer data to be scaled (or normalized), this means they like to have the numbers in tensors they try to find patternsbetween 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get our training and testing data between 0 & 1 by dividing by the maximum\n",
    "train_data_norm = train_data / 255\n",
    "test_data_norm = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our data is normalized, let's build a model to find patterns in it\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating a model\n",
    "clothing_model_norm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "clothing_model_norm.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                            optimizer=tf.keras.optimizers.Adam(),\n",
    "                            metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his_norm = clothing_model_norm.fit(train_data_norm, train_labels, epochs=10, verbose=0, validation_data=(test_data_norm, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "clothing_model_norm.evaluate(test_data_norm, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Plot non-normalized data loss curves\n",
    "pd.DataFrame(his.history).plot(title=\"Non-normalized data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized data loss curves\n",
    "pd.DataFrame(his_norm.history).plot(title=\"Normalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ”‘ **Note:** The same model with even *slightly* different data can produce *dramatically* different results. So when comparing, it's important to make sure we're comparing them on the same criteria (e.g. Same architecture but different data or same data but different architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model for a longer period of time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our data is normalized, let's build a model to find patterns in it\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating a model\n",
    "clothing_model_norm_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "clothing_model_norm_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                            optimizer=tf.keras.optimizers.Adam(),\n",
    "                            metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his_norm = clothing_model_norm_1.fit(train_data_norm, train_labels, epochs=20, verbose=0, validation_data=(test_data_norm, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "clothing_model_norm_1.evaluate(test_data_norm, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using our model\n",
    "predictions = clothing_model_norm_1.predict(test_data_norm)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the confusion matrix of our model\n",
    "clothing_matrix = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "clothing_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting our confusion matrix\n",
    "make_confusion_matrix(clothing_matrix, \"Blues\", \"Clothing confusion matrix\", \"Predicted Values\", \"Actual Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ”‘ **Note:** Often when working with images and other forms of visual data, it's a good idea to visualize as much as possible to devlop a furthur understanding of the data and the inputs and the outputs of your models.\n",
    "\n",
    "How about we create a fun little function for:\n",
    "* Plot a random image\n",
    "* Make a prediction on said image\n",
    "* label the model with the truth table and the predicted table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d5a1ced3a8aacfbfaf550a502c15ba96261cc41be45c758a11f8b6c84637eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to neural network classification with Tensorflow\n",
    "\n",
    "In this notebook we're going to learn how to write neural networks for classification problems.\n",
    "\n",
    "A classification is where you try to classify something as one thing or another\n",
    "* Binary classification\n",
    "* Multiclass classification\n",
    "* Multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Make 1000 circles\n",
    "n_samples = 1000\n",
    "\n",
    "# Create circles\n",
    "X, Y = make_circles(n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(X), Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a little hard to understand right now... Let's visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":Y})\n",
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling\n",
    "\n",
    "The steps in modelling with Tensorflow are typically\n",
    "\n",
    "1. Create or import a model\n",
    "2. Compile the model\n",
    "3. Fit the model\n",
    "4. Evaluate the model\n",
    "5. Tweak\n",
    "6. Evaluate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model using Sequential API\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X, Y, epochs=150, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model_1.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our  model's predictions, let's create a function `plot_decision_boundary()`, this function will:\n",
    "    \n",
    "* Take in a trained model, features (X) and labels(Y)\n",
    "* Create a meshgrid of the different X values\n",
    "* Make predictions across the meshgrid\n",
    "* Plot the predictions as well as line between zones (where each unique class falls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, Y):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary created by a model predicting on X.\n",
    "    \"\"\"\n",
    "    # Define the axis boundary of the plot and create the meshgrid\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Create X value (we're going to make predictions on this)\n",
    "    x_in = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_in)\n",
    "    \n",
    "    # Check for multi-class\n",
    "    if len(y_pred[0]) > 1:\n",
    "        print(\"Doing multiclass classification\")\n",
    "        # We have to reshape our predictions to get them ready for plotting\n",
    "        y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
    "    else:\n",
    "        print(\"Doing binary classification\")\n",
    "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
    "        \n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=0.7)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the predictions our model is making\n",
    "plot_decision_boundary(model=model_1, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "\n",
    "x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Missing Piece: Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = model_2.fit(X, Y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the decision boundary for our latest model\n",
    "plot_decision_boundary(model=model_2, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” **Question:** What's wrong with the predictions we've made? Are we really evaluating our model correctly? Hint: What data did the model learned on and what data did we predict on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy tensor (similar to the data we pass into our models)\n",
    "A = tf.cast(tf.range(-10, 10), tf.float32)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by replicating sigmoid - sigmoid(x) = 1/(1+exp(-x))\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "# Using this sigmoid function now on our toy tensor\n",
    "sigmoid(A)\n",
    "   \n",
    "plt.plot(sigmoid(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the relu function\n",
    "def relu(x):\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "# Let's plot our toy tensor using relu function\n",
    "plt.plot(relu(A))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Improving our classification model\n",
    "\n",
    "So far we've been training and testing on the same dataset...\n",
    "\n",
    "However, in machine learning this is a sin,\n",
    "\n",
    "So let's create a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many examples we have\n",
    "len(X)\n",
    "\n",
    "# Split into train and tests sets\n",
    "X_train, Y_train = X[:800], Y[:800]\n",
    "\n",
    "X_test, Y_test = X[800:], Y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate a model to fit in the training data and evaluating in the testing data\n",
    "\n",
    "# Set a random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "final_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "final_model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = final_model.fit(X_train, Y_train, epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "final_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the decision boundary\n",
    "plot_decision_boundary(model=final_model, X=X_test, Y=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss (or training) curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(his.history).plot()\n",
    "plt.title(\"final_model loss curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”‘ **Note:** For many problems, the loss function goinng down means the model is improving (The predictions it's making are getting closer to the ground truth labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best learning rate\n",
    "\n",
    "To find the ideal learning rate (The learning rate where the loss decreases the most during the training) we're going to use the following steps:\n",
    "* A learning rate **callback** - we can think of a callback as an extra piece of functionality, we can add to the model while its training.\n",
    "* Another  model (we could use the same one as above, but we're practicing building models here).\n",
    "* A modified loss curves plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "from gc import callbacks\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Create a learning rate callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n",
    "\n",
    "# Fit the model\n",
    "his = model_3.fit(X_train, Y_train, epochs=100, callbacks=[lr_scheduler], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model_3\n",
    "model_3.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the plot history\n",
    "pd.DataFrame(his.history).plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_4.fit(X_train, Y_train, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model_4\n",
    "model_4.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More classification evaluation methods\n",
    "\n",
    "Alongside visualizing our models results as much as possible, there are a handful of other classification evaluation methods & metrics we should be fimiliar with\n",
    "* Accuarcy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "* Confusion matrix\n",
    "* Classification report (from sklearn) - [Read the Docs](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of our model\n",
    "loss, accuracy = model_4.evaluate(X_test, Y_test)\n",
    "print(f\"Model loss on the test set: {loss}\")\n",
    "print(f\"Model accuracy on the test set: {(accuracy*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about a confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craete confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions \n",
    "Y_pred = model_4.predict(X_test)\n",
    "\n",
    "# Create a confusion_matrix\n",
    "confusion_matrix(Y_test, tf.squeeze(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our prediction array has turned out in **prediction probability** form... The standard output from the sigmoid activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our prediction probabilities to binary format and view the first 10\n",
    "Y_pred1 = tf.round(Y_pred)\n",
    "Y_pred1 =tf.cast(Y_pred1, dtype=tf.int64)\n",
    "Y_pred1 = tf.squeeze(Y_pred1)\n",
    "Y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_test, Y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about prettify our confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap=\"Oranges\")\n",
    "ax.set_title(\"Seaborn Confusion Matrix with labels\\n\\n\")\n",
    "ax.set_xlabel(\"\\nActual Values\")\n",
    "ax.set_ylabel(\"Predicted Values\")\n",
    "\n",
    "# Plotting the Matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Multiclass Classification\n",
    "\n",
    "When we have more than two classes as an option, it's known as **multi-class-classfication**.\n",
    "* This means if we have 3 differrent classes, it's a multi-class-classfication.\n",
    "* It also means if you have 100 different classes, it's a multi-class-classfication.\n",
    "\n",
    "To practice multi-class-classfication, we're going to build a neural network to classify images of different items of clothing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# The data is already been sorted into training and test sets for us\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first training sample\n",
    "print(f\"Training sample:\\n{train_data[2]}\\n\")\n",
    "print(f\"Training labels: {train_labels[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of a single example\n",
    "train_data[2].shape, train_labels[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single sample\n",
    "plt.imshow(train_data[7]), train_labels[7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d5a1ced3a8aacfbfaf550a502c15ba96261cc41be45c758a11f8b6c84637eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

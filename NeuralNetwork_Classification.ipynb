{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to neural network classification with Tensorflow\n",
    "\n",
    "In this notebook we're going to learn how to write neural networks for classification problems.\n",
    "\n",
    "A classification is where you try to classify something as one thing or another\n",
    "* Binary classification\n",
    "* Multiclass classification\n",
    "* Multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Make 1000 circles\n",
    "n_samples = 1000\n",
    "\n",
    "# Create circles\n",
    "X, Y = make_circles(n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(X), Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a little hard to understand right now... Let's visualize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":Y})\n",
    "circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling\n",
    "\n",
    "The steps in modelling with Tensorflow are typically\n",
    "\n",
    "1. Create or import a model\n",
    "2. Compile the model\n",
    "3. Fit the model\n",
    "4. Evaluate the model\n",
    "5. Tweak\n",
    "6. Evaluate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model using Sequential API\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X, Y, epochs=150, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model_1.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our  model's predictions, let's create a function `plot_decision_boundary()`, this function will:\n",
    "    \n",
    "* Take in a trained model, features (X) and labels(Y)\n",
    "* Create a meshgrid of the different X values\n",
    "* Make predictions across the meshgrid\n",
    "* Plot the predictions as well as line between zones (where each unique class falls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, Y):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary created by a model predicting on X.\n",
    "    \"\"\"\n",
    "    # Define the axis boundary of the plot and create the meshgrid\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    # Create X value (we're going to make predictions on this)\n",
    "    x_in = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_in)\n",
    "    \n",
    "    # Check for multi-class\n",
    "    if len(y_pred[0]) > 1:\n",
    "        print(\"Doing multiclass classification\")\n",
    "        # We have to reshape our predictions to get them ready for plotting\n",
    "        y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
    "    else:\n",
    "        print(\"Doing binary classification\")\n",
    "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
    "        \n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=0.7)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the predictions our model is making\n",
    "plot_decision_boundary(model=model_1, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "\n",
    "x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Missing Piece: Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = model_2.fit(X, Y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the decision boundary for our latest model\n",
    "plot_decision_boundary(model=model_2, X=X, Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” **Question:** What's wrong with the predictions we've made? Are we really evaluating our model correctly? Hint: What data did the model learned on and what data did we predict on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy tensor (similar to the data we pass into our models)\n",
    "A = tf.cast(tf.range(-10, 10), tf.float32)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by replicating sigmoid - sigmoid(x) = 1/(1+exp(-x))\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + tf.exp(-x))\n",
    "\n",
    "# Using this sigmoid function now on our toy tensor\n",
    "sigmoid(A)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmoid(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the relu function\n",
    "def relu(x):\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "# Let's plot our toy tensor using relu function\n",
    "plt.plot(relu(A))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Improving our classification model\n",
    "\n",
    "So far we've been training and testing on the same dataset...\n",
    "\n",
    "However, in machine learning this is a sin,\n",
    "\n",
    "So let's create a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many examples we have\n",
    "len(X)\n",
    "\n",
    "# Split into train and tests sets\n",
    "X_train, Y_train = X[:800], Y[:800]\n",
    "\n",
    "X_test, Y_test = X[800:], Y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate a model to fit in the training data and evaluating in the testing data\n",
    "\n",
    "# Set a random seed\n",
    "from tabnanny import verbose\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model\n",
    "final_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "final_model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "his = final_model.fit(X_train, Y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "final_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the decision boundary\n",
    "plot_decision_boundary(model=final_model, X=X_test, Y=Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d5a1ced3a8aacfbfaf550a502c15ba96261cc41be45c758a11f8b6c84637eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

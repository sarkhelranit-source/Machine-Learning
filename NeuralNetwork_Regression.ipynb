{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raERnoSt3q2e"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in Tensorflow\n",
        "\n",
        "There are many definition for a regression model but in this case, i'm going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjmGtDgB4hxq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import plot_model\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQvJBJVb443N"
      },
      "source": [
        "# Creating Data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi5RJ4Sb49nA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create faetures\n",
        "x = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Craete labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "plt.scatter(x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFuJe5L08o7K"
      },
      "source": [
        "# Input and Output shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsW-6UV8sTU"
      },
      "outputs": [],
      "source": [
        "# Creating a demo tensor for our housing prediction problems\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"kitchen\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info.shape, house_price.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8v-SDQ4953n"
      },
      "outputs": [],
      "source": [
        "x_ten = tf.constant(x)\n",
        "y_ten = tf.constant(y)\n",
        "x_rs = tf.reshape(x_ten, [1, 8])\n",
        "y_rs = tf.reshape(y_ten, [1, 8])\n",
        "x_rs.shape, y_rs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr5kZqNSCV1C"
      },
      "source": [
        "# Steps in modelling with Tensorflow\n",
        "\n",
        "1. **Craeting a model** - define the input and output layers, as well as the hidden layers of a deep learning model\n",
        "2. **Compiling a model** - define a loss function (in other words, the fuction which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns in learning) and evaluation metrices (what we can use to interpret of our model).\n",
        "3. **Fitting the model** - letting the model trying to find patterns between X & Y (features and labels) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOADsL0zDXp5"
      },
      "outputs": [],
      "source": [
        "# Settting a random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_rs, y_rs, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZDHsNmFSsxQ"
      },
      "outputs": [],
      "source": [
        "# Try and make predictions using our model\n",
        "x_rs = tf.constant([[17.0, 20.0, 23.0, 26.0, 29.0, 32.0, 35.0, 38.0]])\n",
        "model.predict(x_rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create our model\n",
        "\n",
        "1. **Craeting a model** - Here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps the learning rate of the optimization function of each layer.\n",
        "3. **Fitting the model** - Here we might fit the model for more epochs (leave it training for longer) or on more data (give the model more examples to learn from)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sisYRw6CrQ5"
      },
      "outputs": [],
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)    \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(x_rs, y_rs, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating a model\n",
        "\n",
        "In practical, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model --> fit it --> tweak the model --> evaluate it...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a bigger dataset\n",
        "x = tf.range(-100, 100, 4)\n",
        "x\n",
        "\n",
        "# Make labels for the dataset\n",
        "y = x + 10\n",
        "y\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The 3 sets...\n",
        "\n",
        "* **Training set** - The model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation set** - The model gets tuned on this data, which is typically 10-15% of the total data you have available\n",
        "* **Test set** - The model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data you have available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the length how many samples we have\n",
        "len(x)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "x_train = x[:40] # First 40 are training samples (80% of the data)\n",
        "y_train = y[:40] # First 40 are training samples (80% of the data)\n",
        "\n",
        "x_test = x[40:] # last 10 are test samples (20% of the data)\n",
        "y_test = y[40:] # last 10 are test samples (20% of the data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the data\n",
        "\n",
        "Now we've got data training and test sets let's visualize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Plot training data in blue\n",
        "plt.scatter(x_train, y_train, c=\"b\", label=\"Training data\")\n",
        "\n",
        "# Plot test data in green\n",
        "plt.scatter(x_test, y_test, c=\"g\", label=\"Test data\")\n",
        "\n",
        "# Show a legend\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building a neural network for our data\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1])\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable params - these are the parameters (patters) the model can update as it trains\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typical when we bring in laready learn patters or parameters from other models during **transfer learning**).\n",
        "\n",
        "ðŸ“– **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out [MIT's Introduction to Deep learning](https://www.youtube.com/watch?v=7sB052Pz0sQ&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) video\n",
        "\n",
        "![image](https://3.bp.blogspot.com/-JYbNelUE66k/XhOdLxanW5I/AAAAAAAACVI/fD375RZr0BAtoosh-e5Zbzz-gEll6bmxwCLcBGAsYHQ/s1600/intro.png)\n",
        "\n",
        "ðŸ›  **Exercise:** Try play around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainble) by calling `model.summary()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the model\n",
        "model.fit(x_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NeuralNetwork_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "9d5a1ced3a8aacfbfaf550a502c15ba96261cc41be45c758a11f8b6c84637eb5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raERnoSt3q2e"
      },
      "source": [
        "# Introduction to Regression with Neural Networks in Tensorflow\n",
        "\n",
        "There are many definition for a regression model but in this case, i'm going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjmGtDgB4hxq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import plot_model\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQvJBJVb443N"
      },
      "source": [
        "# Creating Data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi5RJ4Sb49nA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create faetures\n",
        "x = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Craete labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "plt.scatter(x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFuJe5L08o7K"
      },
      "source": [
        "# Input and Output shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqsW-6UV8sTU"
      },
      "outputs": [],
      "source": [
        "# Creating a demo tensor for our housing prediction problems\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"kitchen\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info.shape, house_price.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8v-SDQ4953n"
      },
      "outputs": [],
      "source": [
        "x_ten = tf.constant(x)\n",
        "y_ten = tf.constant(y)\n",
        "x_rs = tf.reshape(x_ten, [1, 8])\n",
        "y_rs = tf.reshape(y_ten, [1, 8])\n",
        "x_rs.shape, y_rs.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr5kZqNSCV1C"
      },
      "source": [
        "# Steps in modelling with Tensorflow\n",
        "\n",
        "1. **Craeting a model** - define the input and output layers, as well as the hidden layers of a deep learning model\n",
        "2. **Compiling a model** - define a loss function (in other words, the fuction which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns in learning) and evaluation metrices (what we can use to interpret of our model).\n",
        "3. **Fitting the model** - letting the model trying to find patterns between X & Y (features and labels) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOADsL0zDXp5"
      },
      "outputs": [],
      "source": [
        "# Settting a random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x_rs, y_rs, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZDHsNmFSsxQ"
      },
      "outputs": [],
      "source": [
        "# Try and make predictions using our model\n",
        "x_rs = tf.constant([[17.0, 20.0, 23.0, 26.0, 29.0, 32.0, 35.0, 38.0]])\n",
        "model.predict(x_rs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create our model\n",
        "\n",
        "1. **Craeting a model** - Here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - Here we might change the optimization function or perhaps the learning rate of the optimization function of each layer.\n",
        "3. **Fitting the model** - Here we might fit the model for more epochs (leave it training for longer) or on more data (give the model more examples to learn from)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sisYRw6CrQ5"
      },
      "outputs": [],
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(150, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(x_rs, y_rs, epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating a model\n",
        "\n",
        "In practical, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model --> fit it --> tweak the model --> evaluate it...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a bigger dataset\n",
        "x = tf.range(-100.0, 100.0, 4)\n",
        "x\n",
        "# Make labels for the dataset\n",
        "y = x + 10\n",
        "y\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The 3 sets...\n",
        "\n",
        "* **Training set** - The model learns from this data, which is typically 70-80% of the total data you have available.\n",
        "* **Validation set** - The model gets tuned on this data, which is typically 10-15% of the total data you have available\n",
        "* **Test set** - The model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data you have available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the length how many samples we have\n",
        "len(x)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "x_train = x[:40]  # First 40 are training samples (80% of the data)\n",
        "y_train = y[:40]  # First 40 are training samples (80% of the data)\n",
        "\n",
        "x_test = x[40:]  # last 10 are test samples (20% of the data)\n",
        "y_test = y[40:]  # last 10 are test samples (20% of the data)\n",
        "\n",
        "x_train_tensor = tf.constant(x_train)\n",
        "y_train_tensor = tf.constant(y_train)\n",
        "\n",
        "x_test_tensor = tf.constant(x_test)\n",
        "y_test_tensor = tf.constant(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the data\n",
        "\n",
        "Now we've got data training and test sets let's visualize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Plot training data in blue\n",
        "plt.scatter(x_train_tensor, y_train_tensor, c=\"b\", label=\"Training data\")\n",
        "\n",
        "# Plot test data in green\n",
        "plt.scatter(x_test_tensor, y_test_tensor, c=\"g\", label=\"Test data\")\n",
        "\n",
        "# Show a legend\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building a neural network for our data\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
        "    tf.keras.layers.Dense(1, name=\"output_layer\")\n",
        "], name=\"model_1\")\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **Total params** - total number of parameters in the model.\n",
        "* **Trainable params** - these are the parameters (patterns) the model can update as it trains\n",
        "* **Non-trainable params** - these parameters aren't updated during training (this is typical when we bring in laready learn patters or parameters from other models during **transfer learning**).\n",
        "\n",
        "ðŸ“– **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out [MIT's Introduction to Deep learning](https://www.youtube.com/watch?v=7sB052Pz0sQ&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) video\n",
        "\n",
        "![image](https://3.bp.blogspot.com/-JYbNelUE66k/XhOdLxanW5I/AAAAAAAACVI/fD375RZr0BAtoosh-e5Zbzz-gEll6bmxwCLcBGAsYHQ/s1600/intro.png)\n",
        "\n",
        "ðŸ›  **Exercise:** Try play around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainble) by calling `model.summary()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the model\n",
        "model.fit(x_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "plot_model(model=model, show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing our model's prediction\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
        "Often we'll see this in the form of `y_test` or `y_true` vs `y_pred` (ground truth vs model's predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(x_test_tensor)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a plotting function\n",
        "def plot_pred(train_data,\n",
        "              train_labels,\n",
        "              test_data,\n",
        "              test_label,\n",
        "              predictions):\n",
        "    '''\n",
        "    Plots training data, test data and compares predictions to ground truth labels.\n",
        "    '''\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Plot training data in blue\n",
        "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training Data\")\n",
        "    # Plot testing data in green\n",
        "    plt.scatter(test_data, test_label, c=\"g\", label=\"Test Data\")\n",
        "    # Plot model's predictions in red\n",
        "    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "plot_pred(x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test\n",
        "model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the mean absolute error\n",
        "tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                               y_pred=tf.constant(y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.constant(y_pred)\n",
        "tf.reshape(y_pred, shape=(10,))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test_tensor,\n",
        "                                     y_pred=tf.squeeze(y_pred))\n",
        "mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the mean squared error\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test_tensor,\n",
        "                                    y_pred=tf.squeeze(y_pred))\n",
        "mse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Making functions to reuse the MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n",
        "\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running experiments to improve our model\n",
        "\n",
        "1. Get more data\n",
        "2. Make the model larger (using a more complex model)\n",
        "3. Train for longer\n",
        "\n",
        "Let's do 3 modelling experiments\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs.\n",
        "3. `model_3` - 2 layers, trained for 500 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building model 1\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model_1.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(x_train_tensor, y_train_tensor, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_1 = model_1.predict(x_test_tensor)\n",
        "plot_pred(x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, y_pred_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_1 = mae(y_test_tensor, y_pred_1)\n",
        "mse_1 = mse(y_test_tensor, y_pred_1)\n",
        "\n",
        "mae_1, mse_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building model 2\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model_2.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(x_train_tensor, y_train_tensor, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_2 = model_2.predict(x_test_tensor)\n",
        "plot_pred(x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_2 = mae(y_test_tensor, y_pred_2)\n",
        "mse_2 = mse(y_test_tensor, y_pred_2)\n",
        "\n",
        "mae_2, mse_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building model 3\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model_3.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(x_train_tensor, y_train_tensor, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_3 = model_3.predict(x_test_tensor)\n",
        "plot_pred(x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, y_pred_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mae_3 = mae(y_test_tensor, y_pred_3)\n",
        "mse_3 = mse(y_test_tensor, y_pred_3)\n",
        "\n",
        "mae_3, mse_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ”‘ **Note:** Starting with small experiments (small models) and make sure they work and then increase their scale when necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiling the results of our experiments\n",
        "\n",
        "We've run a few experiments, let's compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's compare our model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like `model_2` preformed the best..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ðŸ”‘ **Note:** One of our main goals should be to minimize the time between our experiments. The more experiments we do, the more things we'll figure out which don't work, in turn we'll get closer to figuring out what does work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tracking the experiments\n",
        "\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so it can be tedious if you're running a lots of experiments. \n",
        "\n",
        "Luckily, there are tools to help us\n",
        "\n",
        "ðŸ“– **Resource:** As we build more models we'll want to look into using:\n",
        "\n",
        "* [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) - A component of tensorflow library to help track modelling experiments (We'll see this on later).\n",
        "* [Weights & Biases](https://wandb.ai/site) - A tool for tracking all kinds of machine learning experiments (plugs straight into TensorBoard)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving our models\n",
        "\n",
        "Saving our models allows us to use them outside of Google colab such as in a web application or on a mobile app\n",
        "\n",
        "There are two main formats we can save out model's too:\n",
        "1. The `SaveModel` Format\n",
        "2. The `HDF5` Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model using SaveModel Format\n",
        "model_2.save(\"best_model_SaveModel_format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model using HDF5 Format\n",
        "model_2.save(\"best_model_HDF5_format.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading in a saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load in the SavedModel Format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"best_model_SaveModel_format\")\n",
        "loaded_SavedModel_format.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare model 2 predictions with the SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(y_test_tensor)\n",
        "savedmodel_preds = loaded_SavedModel_format.predict(y_test_tensor)\n",
        "\n",
        "mae(y_test_tensor, model_2_preds) == mae(y_test_tensor, savedmodel_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Larger Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in a Insurance Dataset\n",
        "insurance = pd.read_csv(\"insurance.csv\")\n",
        "insurance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insurance_onehot = pd.get_dummies(insurance)\n",
        "insurance_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craete X and Y values (features and labels)\n",
        "x1 = insurance_onehot.drop(\"charges\", axis=1)\n",
        "y1 = insurance_onehot[\"charges\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craete training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.2, random_state=42)\n",
        "len(x1_train), len(x1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a neural network (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create insurence model\n",
        "model_ins = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_ins.compile(loss=\"mae\",\n",
        "                  optimizer=\"sgd\",\n",
        "                  metrics=[\"mae\"])\n",
        "\n",
        "# Fitting the model\n",
        "model_ins.fit(x1_train, y1_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the results of the insuarnce model on the test data\n",
        "model_ins.evaluate(x1_test, y1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Right now it looks like our model isn't performing very well... let's try to improve it"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NeuralNetwork_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "9d5a1ced3a8aacfbfaf550a502c15ba96261cc41be45c758a11f8b6c84637eb5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
